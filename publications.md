---
title: Publications
---

## 2025–2026

- Mogens From, Jacob Nielsen, Lukas Galke, and Peter Schneider-Kamp (2026). DeToNATION: Decoupled Torch Network-Aware Training on Interlinked Online Nodes. *AAAI*.
- Danial Namazifard and Lukas Galke (2025). Isolating Culture Neurons in Multilingual Large Language Models. *AACL-IJCNLP Findings*. [preprint](https://arxiv.org/abs/2508.02241) [paper](https://aclanthology.org/2025.findings-ijcnlp.45/)
- Richard Šléher, William Brach, Tibor Sloboda, Kristián Košťál, and Lukas Galke (2025). Guarded Query Routing for Large Language Models. *ECAI*. [preprint](https://arxiv.org/abs/2505.14524)
- Marcel Hoffmann, Lukas Galke, and Ansgar Scherp (2025). Gumbel-MPNN: Graph Rewiring with Gumbel-Softmax. *ECAI*.
- Mourad Abbas, Tariq Yousef, and Lukas Galke (Eds.) (2025). Proceedings of the 8th International Conference on Natural Language and Speech Processing (ICNLSP-2025). [proceedings](https://aclanthology.org/2025.icnlsp-1.0/)
- Filippo Tonini and Lukas Galke (2025). Super-additive Cooperation in Language Model Agents. *Springer 3rd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications* (FAIEMA).
- Stine Lyngso Beltoft and Lukas Galke (2025). Not Everything That Counts Can Be Counted: A Case for Safe Qualitative AI. *Springer 3rd International Conference on Frontiers of Artificial Intelligence, Ethics, and Multidisciplinary Applications* (FAIEMA).
- Andrea Blasi Nuñez, Lukas Galke, and Peter Schneider-Kamp (2025). MLDataForge: Accelerating Large-Scale Dataset Preprocessing and Access for Multimodal Foundation Model Training. *RaNLP*.
- Jacob Nielsen, Peter Schneider-Kamp, and Lukas Galke (2025). Continual Quantization-Aware Pre-Training: When to transition from 16-bit to 1.58-bit pre-training for BitNet language models? *ACL Findings*. [preprint](https://arxiv.org/abs/2502.11895)
- Andor Diera, Lukas Galke, and Ansgar Scherp (2025). Isotropy Matters: Soft-ZCA Whitening of Embeddings for Semantic Code Search. *ESANN*. [preprint](https://arxiv.org/abs/2411.17538) [code](https://github.com/drndr/code_isotropy)
- Jacob Nielsen, Lukas Galke, and Peter-Schneider Kamp (2025). When are 1.58 bits enough? A Bottom-up Exploration of Quantization-aware Training with Ternary Weights. *ICAART*. [preprint](https://arxiv.org/abs/2411.05882)
- Lukas Galke, Limor Raviv (2025). Learning and communication pressures in neural networks: Lessons from emergent communication. *Language Development Research* 5(1). [paper](https://doi.org/10.34842/3vr5-5r49) [preprint](https://arxiv.org/abs/2403.14427)
- Andor Diera, Lukas Galke, Fabian Karl, and Ansgar Scherp (2025). Efficient Continual Learning for Small Language Models with a Discrete Key-Value Bottleneck. *ICNLSP*. [paper](https://aclanthology.org/2025.icnlsp-1.17/)
- Thao Anh Dang, Limor Raviv, and Lukas Galke (2025). Tokenization and Morphology in Multilingual Language Models: A Comparative Analysis of mT5 and ByT5. *ICNLSP*. [paper](https://aclanthology.org/2025.icnlsp-1.24/)

## 2024

- Lukas Galke, Yoav Ram, Limor Raviv (2024). Deep neural networks and humans both benefit from compositional language structure. *Nature Communications* 15:10816. [paper](https://rdcu.be/d5f2e) [code](https://github.com/lgalke/easy2deeplearn) [data](https://doi.org/10.5281/zenodo.14205452)
- Eva Seidlmayer, Tetyana Melnychuk, Lukas Galke, Lisa Kühnel, Klaus Tochtermann, Carsten Schultz, Konrad Förstner (2024). Research Topic Displacement and the Lack of Interdisciplinarity: Lessons from the Scientific Response to COVID-19. *Scientometrics*. [paper](https://doi.org/10.1007/s11192-024-05132-x)
- Yousef Younes, Lukas Galke, and Ansgar Scherp (2024). RADAr: A Transformer-based Autoregressive Decoder Architecture for Hierarchical Text Classification. *ECAI*. [paper](https://ebooks.iospress.nl/doi/10.3233/FAIA240661) [code](https://github.com/yousef-younes/RADAr)
- Marcel Hoffmann, Lukas Galke, Ansgar Scherp (2024). POWN: Prototypical Open-world Node Classification. *CoLLAs*. [paper](https://lifelong-ml.cc/Conferences/2024/acceptedpapersandvideos/conf-2024-38) [code](https://github.com/Bobowner/POWN)
- Anh Dang, Limor Raviv, Lukas Galke (2024). Morphology Matters: Probing the Cross-linguistic Morphological Generalization Abilities of Large Language Models through a Wug Test. *CMCL Workshop @ ACL*. [paper](https://aclanthology.org/2024.cmcl-1.15/)
- Lukas Galke, Yoav Ram, Limor Raviv (2024). Learning Pressures and Inductive Biases in Emergent Communication: Parallels between Humans and Deep Neural Networks. *Evolang XV*.
- Anh Dang, Limor Raviv, Lukas Galke (2024). Testing the Linguistic Niche Hypothesis in Large Language Models with a Multilingual Wug Test. *Evolang XV*.

## 2023

- Tetyana Melnychuk, Lukas Galke, Eva Seidlmayer; Stefanie Bröring, Konrad U. Förstner, Klaus Tochtermann, Carsten Schultz (2023). Development of Similarity Measures from Graph-Structured Bibliographic Metadata: An Application to Identify Scientific Convergence. *IEEE Transactions on Engineering Management*. [paper](https://doi.org/10.1109/TEM.2023.3308008)
- Lukas Galke, Iacopo Vagliano, Benedikt Franke, Tobias Zielke, Marcel Hoffmann, Ansgar Scherp (2023). Lifelong Learning on Evolving Graphs Under the Constraints of Imbalanced Classes and New Classes. *Neural Networks* 164, 156-176. [paper](https://pure.mpg.de/rest/items/item_3368482_4/component/file_3510107/content) [code](https://github.com/lgalke/lifelong-learning)
- Marcel Hoffmann, Lukas Galke, Ansgar Scherp (2023). Open-World Lifelong Graph Learning. *IJCNN*. [paper](https://doi.org/10.1109/IJCNN54540.2023.10191071) [code](https://github.com/Bobowner/Open-World-LGL)
- Andor Diera, Abdelhalim Dahou, Lukas Galke, Fabian Karl, Florian Sihler, Ansgar Scherp (2023). GenCodeSearchNet: A Benchmark Test Suite for Evaluating Generalization in Programming Language Understanding. *GenBench Workshop @ EMNLP*. [paper](https://aclanthology.org/2023.genbench-1.2/)
- Lukas Galke, Yoav Ram, Limor Raviv (2023). What makes a language easy to deep-learn? *Protolang 8*.
- Lukas Galke (2023). Representation Learning for Texts and Graphs: A Unified Perspective On Efficiency, Multimodality, and Adaptability. Number 2023/1 in Kiel Computer Science Series. Department of Computer Science. Dissertation, Faculty of Engineering, Kiel University. [pdf](https://doi.org/10.21941/kcss/2023/1)

## 2022

- Iacopo Vagliano, Lukas Galke, Ansgar Scherp (2022). Recommendations for item set completion: on the semantics of item co-occurrence with data sparsity, input size, and input modalities. *Inf Retrieval J* 25, 269–305. [paper](https://doi.org/10.1007/s10791-022-09408-9) [code](https://github.com/lgalke/aae-recommender)
- Lukas Galke, Isabelle Cuber, Christoph Meyer, Henrik Ferdinand Nölscher, Angelina Sonderecker, Ansgar Scherp (2022). General Cross-Architecture Distillation of Pretrained Language Models into Matrix Embeddings. *IJCNN*. [paper](https://doi.org/10.1109/IJCNN55064.2022.9892144)
- Lukas Galke, Ansgar Scherp (2022). Bag-of-Words vs. Graph vs. Sequence in Text Classification: Questioning the Necessity of Text-Graphs and the Surprising Strength of a Wide MLP. *ACL*. [paper](https://doi.org/10.18653/v1/2022.acl-long.279) [code](https://github.com/lgalke/text-clf-baselines)
- Lukas Galke, Yoav Ram, Limor Raviv (2022). Emergent communication for understanding human language evolution: What's missing? *Emergent Communication Workshop @ ICLR*. [paper](https://openreview.net/forum?id=rqUGZQ-0XZ5)
- Lukas Galke (2022). Representation Learning for Texts and Graphs: A Unified Perspective On Efficiency, Multimodality, and Adaptability [selected PhD thesis abstract]. *IEEE Intelligent Informatics Bulletin*, 22(1), 52. [complete issue](https://www.comp.hkbu.edu.hk/~cib/2022/IIB2022_Final.pdf)

## 2021

- Tetyana Melnychuk, Lukas Galke, Eva Seidlmayer, Konrad Ulrich Förster, Klaus Tochtermann, Carsten Schultz (2021). Früherkennung wissenschaftlicher Konvergenz im Hochschulmanagement. *Hochschulmanagement* 16(1). [complete issue](https://www.universitaetsverlagwebler.de/_files/ugd/7bac3c_24fe9adc2e3740178ad5ba98f66d1931.pdf)
- Lukas Galke, Benedikt Franke, Tobias Zielke, Ansgar Scherp (2021). Lifelong Learning of Graph Neural Networks for Open-World Node Classification. *IJCNN*. [paper](https://doi.org/10.1109/IJCNN52387.2021.9533412) [code](https://github.com/lgalke/lifelong-learning)
- Lukas Galke, Eva Seidlmayer, Gavin Lüdemann, Lisa Langnickel, Tetyana Melnychuk, Konrad U Förstner, Klaus Tochtermann, Carsten Schultz (2021). COVID-19++: A Citation-Aware Covid-19 Dataset for the Analysis of Research Dynamics. *IEEE Big Data*. [paper](https://doi.org/10.1109/BigData52589.2021.9671730)

## 2020 and earlier

- Eva Seidlmayer, Jakob Voß, Tatyana Melnychuk, Lukas Galke, Klaus Tochtermann, Carsten Schultz, Konrad U. Förstner (2020). ORCID for Wikidata — Data enrichment for scientometric applications. *Wikidata Workshop @ ISWC*. [paper](https://ceur-ws.org/Vol-2773/paper-09.pdf)
- Lukas Galke, Tetyana Melnychuk, Eva Seidlmayer, Steffen Trog, Konrad U. Förster, Carsten Schultz, Klaus Tochtermann (2019). Inductive Learning of Concept Representations from Library-Scale Bibliographic Corpora. *INFORMATIK*. [paper](https://doi.org/10.18420/inf2019_26)
- Florian Mai, Lukas Galke, Ansgar Scherp (2019). CBOW Is Not All You Need: Combining CBOW with the Compositional Matrix Space Model. *ICLR*. [paper](https://openreview.net/pdf?id=H1MgjoR9tQ) [code](https://github.com/florianmai/word2mat)
- Eva Seidlmayer, Lukas Galke, Tatyana Melnychuk, Carsten Schultz, Klaus Tochtermann, Konrad U. Förstner (2019). Take it Personally — A Python library for enrichment in informetrical applications. *Posters&Demos @ SEMANTICS*. [paper](https://ceur-ws.org/Vol-2451/paper-23.pdf)
- Lukas Galke, Iacopo Vagliano, Ansgar Scherp (2019). Can Graph Neural Networks Go „Online"? An Analysis of Pretraining and Inference. *Representation Learning on Graphs and Manifolds Workshop @ ICLR*. [paper](https://rlgm.github.io/papers/21.pdf)
- Lukas Galke, Florian Mai, Ansgar Scherp (2019). What If We Encoded Words as Matrices and Used Matrix Multiplication as Composition Function [extended abstract]. *INFORMATIK*. [paper](https://doi.org/10.18420/inf2019_47)
- Ahmed Saleh, Tilman Beck, Lukas Galke, Ansgar Scherp (2018). Performance of Ad-Hoc Retrieval Models over Full-Text vs. Titles of Documents. *ICADL*. [paper](https://doi.org/10.1007/978-3-030-04257-8_30)
- Lukas Galke, Florian Mai, Iacopo Vagliano, Ansgar Scherp (2018). Multi-Modal Adversarial Autoencoders for Recommendation of Citations and Subject Labels. *UMAP*. [paper](https://doi.org/10.1145/3209219.3209236)
- Anne Lauscher, Kai Eckert, Lukas Galke, Ansgar Scherp, Syed Tassen Raza Rizvi, Sheraz Ahmed, Andreas Dengel, Philipp Zumstein, Annette Klein (2018). Linked Open Citation Database: Enabling Libraries to Contribute to an Open and Interconnected Citation Graph. *JCDL*. [paper](https://doi.org/10.1145/3197026.3197050)
- Florian Mai, Lukas Galke, Ansgar Scherp (2018). Using Deep Learning for Title-Based Semantic Subject Indexing to Reach Competitive Performance to Full-Text. *JCDL*. [paper](https://doi.org/10.1145/3197026.3197039)
- Iacopo Vagliano, Lukas Galke, Florian Mai, Ansgar Scherp (2018). Using Adversarial Autoencoders for Multi-Modal Automatic Playlist Continuation. *RecSys Challenge Workshop @ RecSys*. [paper](https://doi.org/10.1145/3267471.3267476)
- Lukas Galke, Gunnar Gerstenkorn, Ansgar Scherp (2018). A Case Study of Closed-Domain Response Suggestion with Limited Training Data. *Text-based Information Retrieval Workshop @ DEXA*. [paper](https://doi.org/10.1007/978-3-319-99133-7_18) [code](https://github.com/lgalke/resuggest)
- Lukas Galke, Florian Mai, Alan Schelten, Dennis Brunch, Ansgar Scherp (2017). Using Titles vs. Full-text as Source for Automated Semantic Document Annotation. *K-CAP*. [paper](https://doi.org/10.1145/3148011.3148039)
- Lukas Galke, Ahmed Saleh, Ansgar Scherp (2017). Word Embeddings for Practical Information Retrieval. *INFORMATIK*. [paper](https://doi.org/10.18420/in2017_215) [code (>200 stars, >40 forks)](https://github.com/lgalke/vec4ir)

## Project reports

- Iacopo Vagliano, Till Blume, Lukas Galke, Florian Mai, Ahmed Saleh, Alexandros Pournaras, Nikolaos Gkalelis, Damianos Galanopoulos, Vasileios Mezaris, Ilija Šimić, Vedran Sabol, Aitor Apaolaza, Markel Vigo, Andrea Zielinski, Peter Mutschke (2019). Deliverable 3.3: Technologies for MOVING data processing and visualisation v3.0. [report](http://moving-project.eu/wp-content/uploads/2019/03/moving_d3.3_v1.0.pdf)
- Iacopo Vagliano, Mohammad Abdel-Qader, Till Blume, Falk Böschen, Lukas Galke, Ahmed Saleh, Ansgar Scherp, Vasileios Mezaris, Alexandros Pournaras, Christos Tzelepis, Ilija Šimić, Cecilia di Sciascio, Vedran Sabol, Aitor Apaolaza, Markel Vigo, Tobias Backes, Peter Mutschke (2018). Technologies for MOVING data processing and visualisation v2.0. [report](http://moving-project.eu/wp-content/uploads/2018/03/moving_d3.2_v1.0.pdf)
- Till Blume, Falk Böschen, Lukas Galke, Ahmed Saleh, Ansgar Scherp, Matthias Schulte-Althoff, Chrysa Collyda, Vasileios Mezaris, Alexandros Pournaras, Christos Tzelepis, Peter Hasitschka, Vedran Sabol, Aitor Apaolaza, Markel Vigo, Tobias Backes, Peter Mutschke Thomas Gottron (2017). Technologies for MOVING data processing and visualisation v1.0. [report](http://moving-project.eu/wp-content/uploads/2017/04/moving_d3.1_v1.0.pdf)
